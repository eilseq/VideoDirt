---
# This template is licensed under a Creative Commons 0 1.0 Universal License (CC0 1.0). Public Domain Dedication.

title: 'VidoDirt: experimental video playback for live coding environments'
author:
  - name: Filippo Guida
    affiliation: Milan Conservatory
    email: filippo.guida@icloud.com
abstract: |
  VideoDirt is a software application enabling users to the create and manipulate video
  contents in realtime through pattern-oriented live coding languages. The aim of this project is to make existing
  time management strategies, usually employed for the composition of music contents, available to video artists.
  The realtime mix of complex materials, whether stored in a file or generated by a process, still represent one of the key elements
  for multi-media performance art praxis. As the name suggests, this application is basically an attempt to convert the
  functionalities provided by Dirt, audio sampler for the Tidal programming language, into the graphic domain.
  A solution designed to bring together the efforts of live-coders in a single network, in a way that both musician and visal-artist
  may be able to make a useful contribution to the development of the language itself.
fontsize: 11pt
geometry: margin=2cm
fontfamily: libertine
fontfamily: inconsolata
mainfont: Linux Libertine O
monofont: Inconsolata
bibliography: references.bib
...

# Introduction


## Motivations

Looking at the whole history and the recent evolutions of video-based performative arts, sometimes improperly collected under
the term 'VJing'[@dekker2003synaesthetic], it is clear that there always been a closely resembling between commons workflows
and technical setups used by video-artist and the ones used by musician involved in electronic music production[@lund2009audio;@eskandar2006ve].

All the most famous real-time video processing applications[^1] provide interfaces to easily mix and manipulate samples from a
media-library through manual gestures assisted by a time controller, exactly like their musical counterparts[^2].
Also the graphical programming environments, be they video-oriented[^3] or sound-oriented[^4], are showing very similar interfaces and
increasingly alike functionalities, strongly focused on the generative process definition, so that became difficult to
identify its main goals.

[^1]: Resolume [https://resolume.com], Modul8:[http://www.modul8.ch], vDMX [http://vidvox.net]
[^2]: Ableton Live [https://www.ableton.com] , Bitwig Studio [https://www.bitwig.com], NI's Machine [https://www.native-instruments.com]
[^3]: VVVV [https://vvvv.org], Touch Designer [https://www.derivative.ca], Isadora [https://troikatronix.com]
[^4]: PureData [https://puredata.info] , Max [https://cycling74.com]

Besides those technical aspects, looking at the production of musicians and visual-artists in the past years[@tate], especially the ones who
are using time-based generative techniques, it is clear that there is no longer a clear difference between the two, even less clear
if talking about live-coding performers[@mclean2010live]. So, both from a technical and from an artistic point of view, there are the
basis to define a single ontology for computer based generative arts[@mastersthesis], and for this reason seems to be advisable for the live-coding
community provide strategies that could bring together all the possible contribution to languages improvement.


## Sample as unifying concept

In all the multi-media art praxis, in one way or another, sampling is the act of taking a portion of complex materials,
recorded or generated, and reusing it during the performance, even manipulating it using standard effects.
This means that sample, as concept, represent a cultural key point, and consequently the best choice to lead visual-artists
to the live-coding community.

Also, it represent the easiest choice because the pattern-oriented languages such as Tidal[^6], designed to manage complex applications
through OSC-events generated by the internal process, could be already used to manipulate video contents: it just needs to change the
destination of those events, providing an application that could able to understand them. So, VideoDirt it's just the translation
of the Dirt sampler[^6] to the video domain, in order to limit language changes to a minimum.

[^6]: Tidal [https://tidalcycles.org/]
[^5]: Dirt [https://github.com/tidalcycles/Dirt]

# VideoDirt

## Overview
VideoDirt is an open source Java application based on the Processing library[^7], that can be also used as external library in
Processing sketches. It is capable of receiving OSC messages coming from Tidal language and use them to mix and manipulate
video contents from a media-library. The video decoder is based on GStreamer[^8], a cross-platform native library that allow
the application to decode any kind of video codec and work at best performances.

[^7]: Processing [https://processing.org]
[^8]: GStreamer [http://gstreamer.freedesktop.org]

As said above, VideoDirt functionalities are made in order to limit language changes to a minimum. So it offer basically the
same parameters to each event, without the ones related to audio effects:

• s:        name of the pointed folder
• n:        index of the pointed sample
• sustain:  the duration of the sound in seconds. If don't set, will be used the natural duration of sample.
• begin:    skips the beginning of each sample, shortening them.
• end:      cuts the end of samples, shortening them.
• legato:   inter-onset time between events, in relation to sustain. If don't set, will be played the whole sample.
• cut:      set the cut-group. Every sample the same group will be forced stopped.
• speed:    speed of sample player
• unit:     controls how the speed parameter is interpreted. (see Tidal reference)

The presence of this basic parameters allow VideoDirt to address messages coming from the sample transformer functions
provided by Tidal, applying the same effect to video clips:

• loopAt:   makes sample fit the given number of cycles.
• chop:     turn a pattern of samples into a pattern of sample parts.
• gap:      similar to chop, but only the sample in place is played.
• striate:  kind of granulator, cutting samples into bits and interlacing it together.
• striateL: just like striate, but also loops each sample chunk a number of times specified.
• stut:     applies a type of delay to a pattern.

In addition to the parameters mentioned above, more have been added to manage basic video manipulations in order to
manage the presence of multiple clips simultaneously. All the videos are printed as texture of plane shapes inside a
3D environment, so each clip has 2 parameter to manage the size:

• xsize:    horizontal size of clip, normalized between 0 and 1 in relation to the window size.
• ysize:    vertical size of clip, normalized between 0 and 1 in relation to the window size.

and 3 parameters to manage its position:

• xpos:     horizontal position of clip inside the window, normalized between -1 and 1 from the center.
• ypos:     vertical position of clip inside the window, normalized between -1 and 1 from the center.
• zpos:     Z-axis position, not normalized. Useful to manage video layers and create zoom in/out effects.

There are also some features that provide color, light and compositing effects needs to mix together all
the clips in place. This list is still growing:

• opacity:   describes the transparency-level, where 1 is not transparent at all and 0 is completely transparent.
• exposure:  set the amount of light per unit area, normalized between 0 and 1.
• cutcolor:  cut a selected color from the video. Useful to cut subject from a green screen.
...

## Software Design
The whole software is made three main classes, that represents the Processing library:

• VideoLibrary:
A static class that collect all the videoclips file patches and provide it to the OSC interpreter:

~~~~ {.java}
public class VideoLibrary {
  ...
  public static void load (String library_dir) {
    ...
	}

	public static String getFilename (Object[] osc_args) {
    ...
	}
  ...
}


• VideoClip:
This class offer all the base video functionalities, inherited from the standard Movie (processing.video),
and decode the incoming OSC-message in order to set the next clip in place as described.
The application create a VideoClip instance for each incoming message, that will be disposed once playback has finished.

~~~~ {.java}
public class VideoClip extends Movie {

	VideoClip(PApplet parent, Object[] osc_args) {
		super(parent, VideoLibrary.getFilename(osc_args));
		decodeOSC(args);
	}
  ...
	public void display() {
		...
    //The display function performed in PApplet context
    ...
	}
}
~~~~

• VideoPlayer:
This class provide multi-threading functionalities to manage the high frequency of VideoClip creation.
Each VideoPlayer instance create and manage a single VideoClip instance in a different thread where are performed all
the operation directly connected to messages interpretation and clip setup, in order to save resources and increase performances:

~~~~ {.java}
public class VideoPlayer implements Runnable {
  ...
	public void run() {
		clip = new VideoClip(parent, args);
		clip.play();
    ...
    Thread.sleep(clip.duration());
    ...
		clip.stop();
	}
}
~~~~

• VideoDirt:
A singleton class collecting all the functionalities. This one can be imported into a Processing sketch as external library
and used to print all the video clips alongside other graphic materials defined inside the sketch itself:

~~~~ {.java}
  import videodirt.VideoDirt;

	public void settings() {
		size(640, 360, P3D);      //be sure to set P3D renderer
	}

	public void setup() {
		VideoDirt.init(this, "./dirt-samples");
		textureMode(NORMAL);      //be sure to set normal texture mode
	}

	public void draw() {
		background(0);
		VideoDirt.display();

    /*
      perform other graphic operations here
    */
	}
~~~~


# Conclusion

VideoDirt provides valuable features for video artists and musician who want to get involved in video production.
The user experience from the live-coder point of view appears unchanged, despite the different nature of involved materials.
and that's a fact that can significantly increase the participation of artists in the Tidal community.
The is open-source software under the MIT license, and both the source and the compiled application for every platform (Linkx, OSX, Windows)
re available as a free download from the GitHub repository[^9].

[^8]: VideoDirt [https://github.com/filippoguida/VideoDirt]


# References
